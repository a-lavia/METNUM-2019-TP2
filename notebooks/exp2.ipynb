{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis con KNN\n",
    "## Clasificador en C++ ðŸ’ªðŸ’ª\n",
    "Vamos a probar a nuestro bichito\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir los path al ejecutable de python 3.6 y sus librerÃ­as,\n",
    "de acuerdo al virtual env que estÃ©n corriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜buildâ€™: File exists\n",
      "-- The C compiler identification is GNU 7.4.0\n",
      "-- The CXX compiler identification is GNU 7.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "Release mode\n",
      "-- Found PythonInterp: /home/cris/anaconda3/bin/python (found version \"3.7.3\") \n",
      "-- Found PythonLibs: /home/cris/anaconda3/lib/libpython3.7m.so\n",
      "-- pybind11 v2.3.dev0\n",
      "-- Performing Test HAS_FLTO\n",
      "-- Performing Test HAS_FLTO - Success\n",
      "-- LTO enabled\n",
      "CMAKE_INSTALL_PREFIX=/home/cris/Documents/Facultad/Met Num 2c_2019/TP2/metnum-tp2-20192c\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/cris/Documents/Facultad/Met Num 2c_2019/TP2/metnum-tp2-20192c/build\n",
      "\u001b[35m\u001b[1mScanning dependencies of target tp2_pybind\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object CMakeFiles/tp2_pybind.dir/src/main_pybind.cpp.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/tp2_pybind.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/tp2_pybind.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/tp2_pybind.dir/src/eigen.cpp.o\u001b[0m\n",
      "[ 33%] \u001b[32m\u001b[1mLinking CXX executable tp2_pybind\u001b[0m\n",
      "[ 33%] Built target tp2_pybind\n",
      "\u001b[35m\u001b[1mScanning dependencies of target sentiment\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/sentiment.cpp.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/sentiment.dir/src/eigen.cpp.o\u001b[0m\n",
      "[ 66%] \u001b[32m\u001b[1mLinking CXX shared module sentiment.cpython-37m-x86_64-linux-gnu.so\u001b[0m\n",
      "[ 66%] Built target sentiment\n",
      "\u001b[35m\u001b[1mScanning dependencies of target tp2\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/main.cpp.o\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/knn.cpp.o\u001b[0m\n",
      "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/pca.cpp.o\u001b[0m\n",
      "[ 93%] \u001b[32mBuilding CXX object CMakeFiles/tp2.dir/src/eigen.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable tp2\u001b[0m\n",
      "[100%] Built target tp2\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"Release\"\n",
      "-- Installing: /home/cris/Documents/Facultad/Met Num 2c_2019/TP2/metnum-tp2-20192c/notebooks/sentiment.cpython-37m-x86_64-linux-gnu.so\n"
     ]
    }
   ],
   "source": [
    "!cd .. && git submodule init\n",
    "!cd .. && git submodule update\n",
    "!cd .. && mkdir build\n",
    "!cd ../build/ && rm -rf *\n",
    "!cd ../build && cmake \\\n",
    "  -DPYTHON_EXECUTABLE=\"$(which python)\" \\\n",
    "  -DCMAKE_BUILD_TYPE=Release ..\n",
    "!cd ../build && make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cris/Documents/Facultad/Met Num 2c_2019/TP2/metnum-tp2-20192c/notebooks\n",
      "Python 3.7.3\n"
     ]
    }
   ],
   "source": [
    "# Verifico la correcta instalaciÃ³n. Si no falla el import estÃ¡ OK\n",
    "!pwd\n",
    "!python --version\n",
    "import sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: *.tgz: Cannot open: No such file or directory\n",
      "tar: Error is not recoverable: exiting now\n",
      "Cantidad de documentos: 12500\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "\n",
    "!cd ../data && tar -xvf *.tgz\n",
    "\n",
    "df = pd.read_csv(\"../data/imdb_small.csv\", index_col=0)\n",
    "\n",
    "print(\"Cantidad de documentos: {}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "      <td>12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>12469</td>\n",
       "      <td>2</td>\n",
       "      <td>12085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>test</td>\n",
       "      <td>This show comes up with interesting locations ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>5100_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6275</td>\n",
       "      <td>2</td>\n",
       "      <td>6322</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         type                                             review  label  \\\n",
       "count   12500                                              12500  12500   \n",
       "unique      2                                              12469      2   \n",
       "top      test  This show comes up with interesting locations ...    neg   \n",
       "freq     6275                                                  2   6322   \n",
       "\n",
       "              file  \n",
       "count        12500  \n",
       "unique       12085  \n",
       "top     5100_4.txt  \n",
       "freq             2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instances(df, train_count, test_count):\n",
    "    # particiono cantidad de instancias de test y train\n",
    "    total_train = df[df.type == 'train']\n",
    "    total_test = df[df.type == 'test']\n",
    "\n",
    "    train = total_train.sample(n=train_count,random_state=1)\n",
    "    test = total_test.sample(n=test_count,random_state=1)\n",
    "    \n",
    "    return train, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de instancias de entrenamiento = 100\n",
      "Cantidad de instancias de test = 100\n"
     ]
    }
   ],
   "source": [
    "train, test = get_instances(df, 100, 100)\n",
    "\n",
    "text_train = train[\"review\"]\n",
    "label_train = train[\"label\"]\n",
    "\n",
    "text_test = test[\"review\"]\n",
    "label_test = test[\"label\"]\n",
    "\n",
    "print(\"Cantidad de instancias de entrenamiento = {}\".format(len(text_train)))\n",
    "print(\"Cantidad de instancias de test = {}\".format(len(text_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance : 0.52 pos 0.48 neg\n"
     ]
    }
   ],
   "source": [
    "print(\"Class balance : {} pos {} neg\".format(\n",
    "    (label_train == 'pos').sum() / label_train.shape[0], \n",
    "    (label_train == 'neg').sum() / label_train.shape[0]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def vectorize(text_train, label_train, text_test, label_test, max_features):\n",
    "    vectorizer = CountVectorizer(max_df=0.90, min_df=0.01, max_features=max_features)\n",
    "    \n",
    "    vectorizer.fit(text_train)\n",
    "\n",
    "    X_train, y_train = vectorizer.transform(text_train), (label_train == 'pos').values\n",
    "    X_test, y_test = vectorizer.transform(text_test), (label_test == 'pos').values\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = vectorize(text_train, label_train, text_test, label_test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentiment\n",
    "\n",
    "clf = sentiment.KNNClassifier(10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n",
      "CPU times: user 42.3 ms, sys: 0 ns, total: 42.3 ms\n",
      "Wall time: 42 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# que empiecen los test\n",
    "import sentiment\n",
    "\n",
    "max_features_values = [1000, 1500]\n",
    "train_values = [1000, 2000, 3000, 4000]\n",
    "test_values = [1000]\n",
    "k_values = [250,500, 750, 1000, 1250, 1500, 1750, 2000]\n",
    "\n",
    "#sin pca\n",
    "\n",
    "for ks in k_values:\n",
    "    clf = sentiment.KNNClassifier(ks)\n",
    "    for train_v in train_values:\n",
    "        if ks > train_v:\n",
    "            continue\n",
    "        for test_v in test_values:\n",
    "            train, test = get_instances(df, train_v, test_v)\n",
    "            \n",
    "            text_train = train[\"review\"]\n",
    "            label_train = train[\"label\"]\n",
    "\n",
    "            text_test = test[\"review\"]\n",
    "            label_test = test[\"label\"]\n",
    "            \n",
    "            for max_feat in max_features_values:\n",
    "                X_train, y_train, X_test, y_test = vectorize(text_train, label_train, text_test, label_test, max_feat)\n",
    "                \n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_test)\n",
    "\n",
    "                acc = accuracy_score(y_test, y_pred)\n",
    "                \n",
    "                with open(\"..//data//out_{}//out_{}_{}_{}_{}.txt\".format(max_feat,max_feat,ks,train_v,test_v), \"w\") as f:\n",
    "                    f.write(\"k: {}\\n\".format(ks))\n",
    "                    f.write(\"max_features: {}\\n\".format(max_feat))\n",
    "                    f.write(\"train: {}\\n\".format(len(text_train)))\n",
    "                    f.write(\"test: {}\\n\".format(len(text_test)))\n",
    "                    f.write(\"Accuracy: {}\\n\".format(acc))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
